import bz2
import pandas as pd
from collections import deque, defaultdict
from datetime import datetime
from math import log2

# ------------------------- CONFIG -------------------------
VALID_VERSIONS = {
    "5.0.0.34","5.0.0.46","5.1.0.2","5.4.0.14","5.4.0.100",
    "5.6.0.6","5.6.0.14","7.0.0.16","7.1.0.2","7.1.0.28",
    "7.1.0.64","7.2.0.50","7.4.0.4","7.5.0.20","7.6.0.2",
    "7.6.0.4","7.6.0.24","7.7.0.100","8.0.0.8","8.1.0.2",
    "8.1.0.4","8.1.0.18","8.1.0.22","8.2.0.72","8.3.0.16",
    "9.1.0.16","9.1.0.46"
}
MAX_TIMESTAMP = 1767225600
FILE_PATH = r"C:\Users\katsi\OneDrive\Business_Analytics\Thesis\Data\master-telemetry-sorted.bz2"
OUTPUT_FILE = "final_features2.csv"
MAX_ROWS = 100_000_000
VERSION_RELEASE_FILE = r"C:\Users\katsi\OneDrive\Business_Analytics\Thesis\Data\Fespa & Tekton Versions.txt"

# ------------------------- VERSION RELEASE MAPPING -------------------------
VERSION_RELEASE_TS = {}
with open(VERSION_RELEASE_FILE, "r") as f:
    for line in f:
        if not line.strip():
            continue
        version, date_str = line.strip().split()
        dt = datetime.strptime(date_str, "%d/%m/%Y")
        VERSION_RELEASE_TS[version] = int(dt.timestamp())

sorted_versions = sorted(VALID_VERSIONS, key=lambda v: VERSION_RELEASE_TS[v])

def days_since_newer_version(prev_version, last_ts):
    for v in sorted_versions:
        if VERSION_RELEASE_TS[v] > VERSION_RELEASE_TS[prev_version]:
            next_release_ts = VERSION_RELEASE_TS[v]
            if last_ts >= next_release_ts:
                return (last_ts - next_release_ts) // 86400
            else:
                return 0
    return 0

# ------------------------- WINDOW ACCUMULATOR -------------------------
class WindowAccumulator:
    def __init__(self, window_size_seconds):
        self.window = deque()  # (timestamp, count)
        self.window_size = window_size_seconds
        self.total = 0

    def add(self, timestamp, count=1):
        self.evict_old(timestamp)
        self.window.append((timestamp, count))
        self.total += count

    def evict_old(self, timestamp):
        cutoff = timestamp - self.window_size
        while self.window and self.window[0][0] < cutoff:
            ts, cnt = self.window.popleft()
            self.total -= cnt

    def get_total(self, timestamp):
        self.evict_old(timestamp)
        return self.total

# ------------------------- USER STATS -------------------------
class UserStats:
    def __init__(self):
        self.command_weekly = WindowAccumulator(7*86400)
        self.activity_30d = deque()
        self.sessions = defaultdict(list)
        self.current_session = {}
        self.crash_events = []
        self.event_counter = defaultdict(int)
        self.commands_since_last_upgrade = set()

    def start_session(self, version, ts):
        if version in self.current_session:
            self.sessions[version].append((self.current_session[version], ts))
        self.current_session[version] = ts

    def end_session(self, version, ts):
        if version in self.current_session:
            self.sessions[version].append((self.current_session[version], ts))
            del self.current_session[version]

    def sessions_last_7d(self, version, now):
        cutoff = now - 7*86400
        return sum(1 for start, end in self.sessions[version] if start >= cutoff)

    def add_event(self, ts, event_full):
        if event_full:
            self.event_counter[event_full] += 1
        event_type = event_full.split(None, 1)[0] if event_full else None
        if event_type in ("Command", "Param"):
            self.command_weekly.add(ts)
            self.commands_since_last_upgrade.add(event_full)
        event_date = datetime.utcfromtimestamp(ts).date()
        self.activity_30d.append((ts, event_date))
        self._evict_old(ts)

    def compute_command_entropy(self):
        total = sum(self.event_counter.values())
        if total == 0:
            return 0
        entropy = sum(-(v/total)*log2(v/total) for v in self.event_counter.values())
        return round(entropy, 2)

    def reset_event_counter(self):
        self.event_counter = defaultdict(int)

    def _evict_old(self, now_ts):
        cutoff = now_ts - 30*86400
        while self.activity_30d and self.activity_30d[0][0] < cutoff:
            self.activity_30d.popleft()

    def get_command_weekly(self, ts):
        return self.command_weekly.get_total(ts)

    def days_active_last_30(self, now):
        self._evict_old(now)
        return len({date for ts, date in self.activity_30d})

    def total_usage_hours_last_7d(self, version, now_ts):
        start_window = now_ts - 7*86400
        total_seconds = 0
        for start, end in self.sessions.get(version, []):
            end_time = end if end is not None else min(now_ts, start + 7*86400)
            overlap_start = max(start, start_window)
            overlap_end = min(end_time, now_ts)
            if overlap_end > overlap_start:
                total_seconds += (overlap_end - overlap_start)
        return total_seconds / 3600

    def add_crash(self, ts):
        self.crash_events.append(ts)

    def crash_count_since(self, last_upgrade_ts, current_ts):
        return sum(1 for ts in self.crash_events if last_upgrade_ts <= ts < current_ts)

    def sessions_since(self, version, last_upgrade_ts, current_ts):
        count = 0
        for start, end in self.sessions.get(version, []):
            if end is None:
                end = current_ts
            if end > last_upgrade_ts and start < current_ts:
                count += 1
        return count

# ------------------------- GLOBAL STATE -------------------------
user_stats = {}
user_versions_seen = {}
version_tuple_cache = {}
version_event_types = defaultdict(set)
last_user_use_ts = {}

def get_user(user_id):
    if user_id not in user_stats:
        user_stats[user_id] = UserStats()
    return user_stats[user_id]

def parse_version(version):
    if version not in version_tuple_cache:
        version_tuple_cache[version] = tuple(map(int, version.split('.')))
    return version_tuple_cache[version]

def parse_line(line):
    fields = line.rstrip("\n").split("\t")
    if len(fields) < 4:
        return None
    try:
        ts = int(float(fields[0]))
        user_id = int(fields[1])
        version = fields[2]
        event_full = fields[3]
    except:
        return None
    if ts >= MAX_TIMESTAMP or user_id < 0 or version not in VALID_VERSIONS:
        return None
    return ts, user_id, version, event_full

seen_rows = set()

def process_upgrade_row(ts, user_id, version, user, sessions_last_7d=0,
                        total_usage_hours=0, crash_count=0, last_version_used=None,
                        error_rate=0, command_entropy=0, unique_events_in_version=0,
                        unique_command_count=0, days_since_newer_version_release=None,
                        days_since_last_use=None):
    key = (ts, user_id, version, user.get_command_weekly(ts),
           user.days_active_last_30(ts), sessions_last_7d, total_usage_hours)
    if key not in seen_rows:
        seen_rows.add(key)
        return {
            'timestamp': ts,
            'user': user_id,
            'version': version,
            'command_param_count_weekly': user.get_command_weekly(ts),
            'days_active_last_30': user.days_active_last_30(ts),
            'sessions_last_7d': sessions_last_7d,
            'total_usage_time_hours': total_usage_hours,
            'crash_count': crash_count,
            'last_version_used': last_version_used,
            'error_rate': error_rate,
            'command_entropy': command_entropy,
            'unique_events_in_version': unique_events_in_version,
            'unique_command_count': unique_command_count,
            'days_since_newer_version_release': days_since_newer_version_release,
            'days_since_last_use': days_since_last_use
        }
    return None

# ------------------------- PROCESS FILE -------------------------
CHUNK_SIZE = 100_000
PROGRESS_INTERVAL = 10_000_000
buffer_rows = []
line_counter = 0
header_written = False

with bz2.open(FILE_PATH, "rt", encoding="utf-8") as f:
    for line in f:
        line_counter += 1
        if line_counter > MAX_ROWS:
            break
        if line_counter % PROGRESS_INTERVAL == 0:
            print(f"Processed {line_counter} rows...")

        parsed = parse_line(line)
        if parsed is None:
            continue

        ts, user_id, version, event_full = parsed
        event_type = event_full.split(None, 1)[0] if event_full else None
        user = get_user(user_id)

        last_use_before_event = last_user_use_ts.get(user_id, ts)
        last_user_use_ts[user_id] = ts

        user.add_event(ts, event_full)

        if event_type in ("Command", "Param"):
            version_event_types[version].add(event_full)

        if event_type == "Start":
            user.start_session(version, ts)

            versions_seen = user_versions_seen.get(user_id, set())
            current_version_tuple = parse_version(version)
            is_upgrade = all(current_version_tuple > parse_version(v) for v in versions_seen) if versions_seen else False
            prev_version = max(versions_seen, key=parse_version) if versions_seen else None
            versions_seen.add(version)
            user_versions_seen[user_id] = versions_seen

            if is_upgrade:
                sessions_last_7d = user.sessions_last_7d(prev_version, ts) if prev_version else 0
                total_usage_hours = round(user.total_usage_hours_last_7d(prev_version, ts), 2) if prev_version else 0
                last_upgrade_ts = user_versions_seen.get(f"{user_id}_last_upgrade_ts", 0)
                crash_count = user.crash_count_since(last_upgrade_ts, ts)
                sessions_count = user.sessions_since(prev_version, last_upgrade_ts, ts) if prev_version else 0
                error_rate = round(crash_count / sessions_count, 2) if sessions_count > 0 else 0
                unique_command_count = len(user.commands_since_last_upgrade)
                user.commands_since_last_upgrade.clear()
                command_entropy = user.compute_command_entropy()
                unique_events_in_new_version = len(version_event_types[version])
                user.reset_event_counter()
                user_versions_seen[f"{user_id}_last_upgrade_ts"] = ts
                days_since_newer = days_since_newer_version(prev_version, ts) if prev_version else None
                days_since_last_use = (ts - last_use_before_event) // 86400 if ts > last_use_before_event else 0

                row = process_upgrade_row(
                    ts, user_id, version, user,
                    sessions_last_7d=sessions_last_7d,
                    total_usage_hours=total_usage_hours,
                    crash_count=crash_count,
                    last_version_used=prev_version,
                    error_rate=error_rate,
                    command_entropy=command_entropy,
                    unique_events_in_version=unique_events_in_new_version,
                    unique_command_count=unique_command_count,
                    days_since_newer_version_release=days_since_newer,
                    days_since_last_use=days_since_last_use
                )
                if row is not None:
                    buffer_rows.append(row)

        elif event_type in ("End", "Crash"):
            user.end_session(version, ts)
            if event_type == "Crash":
                user.add_crash(ts)

        if line_counter % CHUNK_SIZE == 0 and buffer_rows:
            pd.DataFrame(buffer_rows).to_csv(
                OUTPUT_FILE, mode='a', header=not header_written, index=False
            )
            header_written = True
            buffer_rows = []

if buffer_rows:
    pd.DataFrame(buffer_rows).to_csv(
        OUTPUT_FILE, mode='a', header=not header_written, index=False
    )

print(f"Finished processing {line_counter} rows. Upgrade events saved to {OUTPUT_FILE}")
